# Dockerized-Jupyter-Notebook-Environment
# ETL Data Engineering with Docker (AdaBoost Classification)

This project demonstrates how to build an **ETL (Extract, Transform, Load)** pipeline using **Docker** to perform AdaBoost classification. The goal is to show how you can manage data engineering and machine learning workflows inside a containerized environment, making it easy for colleagues or collaborators to run your work without needing Anaconda or any complex setups on their local machines.

## Project Overview

This project consists of:
- A **Dockerfile** to containerize the environment.  This file contains the steps to create a Docker image for this project, including installing Python and the required libraries.
- A **requirements.txt** file to list the required Python dependencies.Libraries listed here are `numpy`, `pandas`, `scikit-learn.
- A **Jupyter notebook** that implements an AdaBoost classifier for data classification.

I built an isolated environment that ensures consistency across all systems, meaning that the project will run exactly the same way regardless of where it's executed.




